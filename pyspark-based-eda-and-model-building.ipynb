{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <div style=\"font-family: Trebuchet MS; background-color: #58D68D; color: #000000; padding: 12px; line-height: 1.5; font-size:\"> Introduction ðŸŽ»</div>\n\n### <div style=\"font-family: Trebuchet MS; background-color: #F4D03F; color: #000000; padding: 12px; line-height: 1.5;\"> Hey Kagglers!! Today I am gonna share with you a simple tool that you can leverage to speeden up the big data processing involved in your own projects. For freshers/experienced practioners, I believe that it is important for y'all to get a basic understanding of the Spark ecosystem as many data-centric companies are continuing to adopt this technology.<br><br> In this notebook, I have tried to compile all the basic functionalities to get you started with Spark effortlessly.</div>\n\n<div style=\"font-family: Trebuchet MS; background-color: #EAECEE; color: #000000; padding: 12px; line-height: 1;\"><h3> Some basic guidelines that I have followed to make this notebook look interactive:</h3><h4><ul style=â€œlist-style-type:squareâ€><li>Whenever there is a definition, I have highlighted it with a  <span style=\"background-color: #2E31FD;font-size: 25px\">ðŸ“£</span></li><br><li>Whenever there is a new function/method, I have highlighted it with a <span style=\"background-color: #00FF00;font-size: 25px\">ðŸŒ¼</span></li><br><li>Whenever there is a suggestion from my side, I have highlighted it with a <span style=\"background-color: #F3FF00;font-size: 25px\">ðŸ“Œ</span></li></ul></h4></div> ","metadata":{}},{"cell_type":"markdown","source":"### So what are you waiting for! Let's get started with the basics:","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"padding: 12px\"><span style=\"background-color: #2E31FD;font-size: 35px\">ðŸ“£</span> What is Apache Spark in Technical terms.</div>\n\n- Apache Spark is an open-source, distributed data processing and analytics framework designed for large-scale data processing tasks. \n\n- It provides a unified and flexible platform for performing various data processing operations, including batch processing, interactive queries, real-time stream processing, machine learning, and graph processing.","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"padding: 12px\"><span style=\"background-color: #2E31FD;font-size: 35px\">ðŸ“£</span> What is this Apache Spark with a simple analogy? </div>\n\n- Apache Spark is like a supercharged engine for processing and analyzing really big piles of data. Imagine you have a massive amount of information, like a gigantic puzzle with millions of pieces. Trying to solve this puzzle on a single computer could take forever. But Spark lets you use many computers at once, like a team of puzzle solvers, to work on different parts of the puzzle together.\n\n- These \"puzzle solvers\" (computers) can talk to each other and share their findings, making the work faster and more efficient. Spark also keeps everything organized and makes sure that even if one of the \"puzzle solvers\" takes a break or has a problem, the others can still continue working without losing progress.\n\n- In simple words, Apache Spark helps you process huge amounts of data much faster by getting a bunch of computers to work together and collaborate on the job. It's like a team effort that makes solving big data problems much easier and quicker!","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"padding: 12px\"><span style=\"background-color: #2E31FD;font-size: 35px\">ðŸ“£</span> What is PySpark?</div>\n\n- PySpark is the Python API to use Spark, just like Pandas.\n\n- In simple words, PySpark is a special tool that combines the power of many computers with the simplicity of Python to help you handle really big piles of data without breaking a sweat!","metadata":{}},{"cell_type":"markdown","source":"## <div style=\"padding: 12px\"><span style=\"background-color: #2E31FD;font-size: 35px\">ðŸ“£</span> Benefits of using PySpark over Pandas for Data Processing:</div>\n\n#### 1. Scalability and Distributed Computing:\n\n- PySpark is designed for processing large-scale data across clusters of machines. It can handle data sizes that may not fit in memory, as it utilizes distributed computing.\n- Pandas, on the other hand, is designed for single-machine data processing and may struggle with extremely large datasets that exceed available memory.\n\n#### 2. Performance:\n\n- PySpark's in-memory processing and distributed computing can lead to better performance for certain operations on large datasets compared to pandas.\n- While pandas is fast for single-machine operations, PySpark's parallel processing can provide significant performance gains for operations that can be parallelized across multiple nodes.","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"font-family: Trebuchet MS; background-color: #B0E0E6; color: #000000; padding: 12px; line-height: 1.5;\"> Importing Libraries ðŸ“š</div>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nimport regex as re\nimport os\n\n## Supressing warnings:\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-19T19:28:18.203222Z","iopub.execute_input":"2023-08-19T19:28:18.203634Z","iopub.status.idle":"2023-08-19T19:28:18.209935Z","shell.execute_reply.started":"2023-08-19T19:28:18.203604Z","shell.execute_reply":"2023-08-19T19:28:18.208722Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:18.212086Z","iopub.execute_input":"2023-08-19T19:28:18.212620Z","iopub.status.idle":"2023-08-19T19:28:31.566451Z","shell.execute_reply.started":"2023-08-19T19:28:18.212566Z","shell.execute_reply":"2023-08-19T19:28:31.565309Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyspark in /opt/conda/lib/python3.10/site-packages (3.4.1)\nRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n","output_type":"stream"}]},{"cell_type":"code","source":"## importing essential spark libraries:\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, split, count, when, regexp_replace, isnan, udf\nfrom pyspark.sql.types import StructField, StructType, StringType, IntegerType, FloatType","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:31.568975Z","iopub.execute_input":"2023-08-19T19:28:31.569367Z","iopub.status.idle":"2023-08-19T19:28:31.577372Z","shell.execute_reply.started":"2023-08-19T19:28:31.569327Z","shell.execute_reply":"2023-08-19T19:28:31.576116Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"font-family: Trebuchet MS; background-color: #B0E0E6; color: #000000; padding: 12px; line-height: 1.5;\"> Getting Started with the Analysis ðŸ”¬</div>\n\n\n#### The first step towards your adventure in Spark is to create a Spark Session. It is the entry point to the Spark ecosystem. Once you<br><br>reach the Spark environment via the entry point, you can freely create and manipulate Spark RDDs, Dataframes and Datasets. ","metadata":{}},{"cell_type":"markdown","source":"## <span style=\"background-color: #2E31FD;font-size: 35px\">ðŸ“£</span> What is a RDD?\n\nYou might be wondering what this new term is. Well RDD stands for **Resilient Distributed Dataset**. It is the fundamental data structure of Spark.","metadata":{}},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> SparkSession.builder()\n\n#### SparkSession will be created using SparkSession.builder() builder patterns::","metadata":{}},{"cell_type":"code","source":"##  Creating a Spark session:\nspark = SparkSession.builder.appName('Sample').getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:31.578922Z","iopub.execute_input":"2023-08-19T19:28:31.579368Z","iopub.status.idle":"2023-08-19T19:28:31.593137Z","shell.execute_reply.started":"2023-08-19T19:28:31.579328Z","shell.execute_reply":"2023-08-19T19:28:31.591847Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"## Quick glance at the object\nspark","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:31.595668Z","iopub.execute_input":"2023-08-19T19:28:31.595978Z","iopub.status.idle":"2023-08-19T19:28:31.606483Z","shell.execute_reply.started":"2023-08-19T19:28:31.595952Z","shell.execute_reply":"2023-08-19T19:28:31.605336Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7bc7a4a91ed0>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://82eccc80c031:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.4.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Sample</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"cell_type":"markdown","source":"##### Here, the spark object acts as the gateway to the Spark ecosystem. \n\n### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> read.csv(), show()\n\n##### Next in order to read the CSV data, we use the **read.csv** functionality:","metadata":{}},{"cell_type":"code","source":"df=spark.read.csv(\"/kaggle/input/food-delivery-dataset/train.csv\",\n                  header=True,\n                  inferSchema=True)\n#  Parameters:\n## - inferSchema parameter ensures that the data formatting stays the same as the original dataframe. If False, then the \n##     columns will be of class string.\n## - header parameter tells that the columns names are provided along with the dataset.\n\n## Displaying the first 5 rows:\ndf.show(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:31.607810Z","iopub.execute_input":"2023-08-19T19:28:31.608644Z","iopub.status.idle":"2023-08-19T19:28:32.363668Z","shell.execute_reply.started":"2023-08-19T19:28:31.608611Z","shell.execute_reply":"2023-08-19T19:28:32.362487Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-------------------+--------------------+--------------------+-----------------+-------------+---------------+-------------------+--------+--------------+---------------+\n|     ID|Delivery_person_ID|Delivery_person_Age|Delivery_person_Ratings|Restaurant_latitude|Restaurant_longitude|Delivery_location_latitude|Delivery_location_longitude|Order_Date|Time_Orderd|  Time_Order_picked|   Weatherconditions|Road_traffic_density|Vehicle_condition|Type_of_order|Type_of_vehicle|multiple_deliveries|Festival|          City|Time_taken(min)|\n+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-------------------+--------------------+--------------------+-----------------+-------------+---------------+-------------------+--------+--------------+---------------+\n|0x4607 |   INDORES13DEL02 |               37.0|                    4.9|          22.745049|           75.892471|                 22.765049|                  75.912471|19-03-2022|   11:30:00|2023-08-19 11:45:00|    conditions Sunny|               High |                2|       Snack |    motorcycle |                0.0|     No |        Urban |       (min) 24|\n|0xb379 |   BANGRES18DEL02 |               34.0|                    4.5|          12.913041|           77.683237|                 13.043041|                  77.813237|25-03-2022|   19:45:00|2023-08-19 19:50:00|   conditions Stormy|                Jam |                2|       Snack |       scooter |                1.0|     No |Metropolitian |       (min) 33|\n|0x5d6d |   BANGRES19DEL01 |               23.0|                    4.4|          12.914264|             77.6784|                 12.924264|                    77.6884|19-03-2022|   08:30:00|2023-08-19 08:45:00|conditions Sandst...|                Low |                0|      Drinks |    motorcycle |                1.0|     No |        Urban |       (min) 26|\n|0x7a6a |  COIMBRES13DEL02 |               38.0|                    4.7|          11.003669|           76.976494|                 11.053669|                  77.026494|05-04-2022|   18:00:00|2023-08-19 18:10:00|    conditions Sunny|             Medium |                0|      Buffet |    motorcycle |                1.0|     No |Metropolitian |       (min) 21|\n|0x70a2 |   CHENRES12DEL01 |               32.0|                    4.6|          12.972793|           80.249982|                 13.012793|                  80.289982|26-03-2022|   13:30:00|2023-08-19 13:45:00|   conditions Cloudy|               High |                1|       Snack |       scooter |                1.0|     No |Metropolitian |       (min) 30|\n+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-------------------+--------------------+--------------------+-----------------+-------------+---------------+-------------------+--------+--------------+---------------+\nonly showing top 5 rows\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> toPandas(), head()","metadata":{}},{"cell_type":"code","source":"## To convert a spark dataframe into a pandas dataframe\ndf.toPandas().head()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:32.364925Z","iopub.execute_input":"2023-08-19T19:28:32.365367Z","iopub.status.idle":"2023-08-19T19:28:35.444726Z","shell.execute_reply.started":"2023-08-19T19:28:32.365330Z","shell.execute_reply":"2023-08-19T19:28:35.443600Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"        ID Delivery_person_ID  Delivery_person_Age  Delivery_person_Ratings  \\\n0  0x4607     INDORES13DEL02                  37.0                      4.9   \n1  0xb379     BANGRES18DEL02                  34.0                      4.5   \n2  0x5d6d     BANGRES19DEL01                  23.0                      4.4   \n3  0x7a6a    COIMBRES13DEL02                  38.0                      4.7   \n4  0x70a2     CHENRES12DEL01                  32.0                      4.6   \n\n   Restaurant_latitude  Restaurant_longitude  Delivery_location_latitude  \\\n0            22.745049             75.892471                   22.765049   \n1            12.913041             77.683237                   13.043041   \n2            12.914264             77.678400                   12.924264   \n3            11.003669             76.976494                   11.053669   \n4            12.972793             80.249982                   13.012793   \n\n   Delivery_location_longitude  Order_Date Time_Orderd   Time_Order_picked  \\\n0                    75.912471  19-03-2022    11:30:00 2023-08-19 11:45:00   \n1                    77.813237  25-03-2022    19:45:00 2023-08-19 19:50:00   \n2                    77.688400  19-03-2022    08:30:00 2023-08-19 08:45:00   \n3                    77.026494  05-04-2022    18:00:00 2023-08-19 18:10:00   \n4                    80.289982  26-03-2022    13:30:00 2023-08-19 13:45:00   \n\n       Weatherconditions Road_traffic_density  Vehicle_condition  \\\n0       conditions Sunny                High                   2   \n1      conditions Stormy                 Jam                   2   \n2  conditions Sandstorms                 Low                   0   \n3       conditions Sunny              Medium                   0   \n4      conditions Cloudy                High                   1   \n\n  Type_of_order Type_of_vehicle  multiple_deliveries Festival            City  \\\n0        Snack      motorcycle                   0.0      No           Urban    \n1        Snack         scooter                   1.0      No   Metropolitian    \n2       Drinks      motorcycle                   1.0      No           Urban    \n3       Buffet      motorcycle                   1.0      No   Metropolitian    \n4        Snack         scooter                   1.0      No   Metropolitian    \n\n  Time_taken(min)  \n0        (min) 24  \n1        (min) 33  \n2        (min) 26  \n3        (min) 21  \n4        (min) 30  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Delivery_person_ID</th>\n      <th>Delivery_person_Age</th>\n      <th>Delivery_person_Ratings</th>\n      <th>Restaurant_latitude</th>\n      <th>Restaurant_longitude</th>\n      <th>Delivery_location_latitude</th>\n      <th>Delivery_location_longitude</th>\n      <th>Order_Date</th>\n      <th>Time_Orderd</th>\n      <th>Time_Order_picked</th>\n      <th>Weatherconditions</th>\n      <th>Road_traffic_density</th>\n      <th>Vehicle_condition</th>\n      <th>Type_of_order</th>\n      <th>Type_of_vehicle</th>\n      <th>multiple_deliveries</th>\n      <th>Festival</th>\n      <th>City</th>\n      <th>Time_taken(min)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x4607</td>\n      <td>INDORES13DEL02</td>\n      <td>37.0</td>\n      <td>4.9</td>\n      <td>22.745049</td>\n      <td>75.892471</td>\n      <td>22.765049</td>\n      <td>75.912471</td>\n      <td>19-03-2022</td>\n      <td>11:30:00</td>\n      <td>2023-08-19 11:45:00</td>\n      <td>conditions Sunny</td>\n      <td>High</td>\n      <td>2</td>\n      <td>Snack</td>\n      <td>motorcycle</td>\n      <td>0.0</td>\n      <td>No</td>\n      <td>Urban</td>\n      <td>(min) 24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0xb379</td>\n      <td>BANGRES18DEL02</td>\n      <td>34.0</td>\n      <td>4.5</td>\n      <td>12.913041</td>\n      <td>77.683237</td>\n      <td>13.043041</td>\n      <td>77.813237</td>\n      <td>25-03-2022</td>\n      <td>19:45:00</td>\n      <td>2023-08-19 19:50:00</td>\n      <td>conditions Stormy</td>\n      <td>Jam</td>\n      <td>2</td>\n      <td>Snack</td>\n      <td>scooter</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>Metropolitian</td>\n      <td>(min) 33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x5d6d</td>\n      <td>BANGRES19DEL01</td>\n      <td>23.0</td>\n      <td>4.4</td>\n      <td>12.914264</td>\n      <td>77.678400</td>\n      <td>12.924264</td>\n      <td>77.688400</td>\n      <td>19-03-2022</td>\n      <td>08:30:00</td>\n      <td>2023-08-19 08:45:00</td>\n      <td>conditions Sandstorms</td>\n      <td>Low</td>\n      <td>0</td>\n      <td>Drinks</td>\n      <td>motorcycle</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>Urban</td>\n      <td>(min) 26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x7a6a</td>\n      <td>COIMBRES13DEL02</td>\n      <td>38.0</td>\n      <td>4.7</td>\n      <td>11.003669</td>\n      <td>76.976494</td>\n      <td>11.053669</td>\n      <td>77.026494</td>\n      <td>05-04-2022</td>\n      <td>18:00:00</td>\n      <td>2023-08-19 18:10:00</td>\n      <td>conditions Sunny</td>\n      <td>Medium</td>\n      <td>0</td>\n      <td>Buffet</td>\n      <td>motorcycle</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>Metropolitian</td>\n      <td>(min) 21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x70a2</td>\n      <td>CHENRES12DEL01</td>\n      <td>32.0</td>\n      <td>4.6</td>\n      <td>12.972793</td>\n      <td>80.249982</td>\n      <td>13.012793</td>\n      <td>80.289982</td>\n      <td>26-03-2022</td>\n      <td>13:30:00</td>\n      <td>2023-08-19 13:45:00</td>\n      <td>conditions Cloudy</td>\n      <td>High</td>\n      <td>1</td>\n      <td>Snack</td>\n      <td>scooter</td>\n      <td>1.0</td>\n      <td>No</td>\n      <td>Metropolitian</td>\n      <td>(min) 30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### As you can see above, Time_taken(min) is the target variable.","metadata":{}},{"cell_type":"markdown","source":"#### Now we have read the csv file into Spark. Lets view the dataframe:","metadata":{}},{"cell_type":"code","source":"## Viewing the type\ntype(df)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:35.446282Z","iopub.execute_input":"2023-08-19T19:28:35.447420Z","iopub.status.idle":"2023-08-19T19:28:35.453523Z","shell.execute_reply.started":"2023-08-19T19:28:35.447386Z","shell.execute_reply":"2023-08-19T19:28:35.452408Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"pyspark.sql.dataframe.DataFrame"},"metadata":{}}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> printSchema()\n\n#### Printing the schema of the dataframe","metadata":{}},{"cell_type":"code","source":"## Printing the attributes of the table:\ndf.printSchema()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:35.455442Z","iopub.execute_input":"2023-08-19T19:28:35.455792Z","iopub.status.idle":"2023-08-19T19:28:35.469753Z","shell.execute_reply.started":"2023-08-19T19:28:35.455761Z","shell.execute_reply":"2023-08-19T19:28:35.468808Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"root\n |-- ID: string (nullable = true)\n |-- Delivery_person_ID: string (nullable = true)\n |-- Delivery_person_Age: double (nullable = true)\n |-- Delivery_person_Ratings: double (nullable = true)\n |-- Restaurant_latitude: double (nullable = true)\n |-- Restaurant_longitude: double (nullable = true)\n |-- Delivery_location_latitude: double (nullable = true)\n |-- Delivery_location_longitude: double (nullable = true)\n |-- Order_Date: string (nullable = true)\n |-- Time_Orderd: string (nullable = true)\n |-- Time_Order_picked: timestamp (nullable = true)\n |-- Weatherconditions: string (nullable = true)\n |-- Road_traffic_density: string (nullable = true)\n |-- Vehicle_condition: integer (nullable = true)\n |-- Type_of_order: string (nullable = true)\n |-- Type_of_vehicle: string (nullable = true)\n |-- multiple_deliveries: double (nullable = true)\n |-- Festival: string (nullable = true)\n |-- City: string (nullable = true)\n |-- Time_taken(min): string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## Displaying the first 5 rows in the form of col-value pairs\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:35.471372Z","iopub.execute_input":"2023-08-19T19:28:35.471717Z","iopub.status.idle":"2023-08-19T19:28:35.536439Z","shell.execute_reply.started":"2023-08-19T19:28:35.471688Z","shell.execute_reply":"2023-08-19T19:28:35.535618Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"[Row(ID='0x4607 ', Delivery_person_ID='INDORES13DEL02 ', Delivery_person_Age=37.0, Delivery_person_Ratings=4.9, Restaurant_latitude=22.745049, Restaurant_longitude=75.892471, Delivery_location_latitude=22.765049, Delivery_location_longitude=75.912471, Order_Date='19-03-2022', Time_Orderd='11:30:00', Time_Order_picked=datetime.datetime(2023, 8, 19, 11, 45), Weatherconditions='conditions Sunny', Road_traffic_density='High ', Vehicle_condition=2, Type_of_order='Snack ', Type_of_vehicle='motorcycle ', multiple_deliveries=0.0, Festival='No ', City='Urban ', Time_taken(min)='(min) 24'),\n Row(ID='0xb379 ', Delivery_person_ID='BANGRES18DEL02 ', Delivery_person_Age=34.0, Delivery_person_Ratings=4.5, Restaurant_latitude=12.913041, Restaurant_longitude=77.683237, Delivery_location_latitude=13.043041, Delivery_location_longitude=77.813237, Order_Date='25-03-2022', Time_Orderd='19:45:00', Time_Order_picked=datetime.datetime(2023, 8, 19, 19, 50), Weatherconditions='conditions Stormy', Road_traffic_density='Jam ', Vehicle_condition=2, Type_of_order='Snack ', Type_of_vehicle='scooter ', multiple_deliveries=1.0, Festival='No ', City='Metropolitian ', Time_taken(min)='(min) 33'),\n Row(ID='0x5d6d ', Delivery_person_ID='BANGRES19DEL01 ', Delivery_person_Age=23.0, Delivery_person_Ratings=4.4, Restaurant_latitude=12.914264, Restaurant_longitude=77.6784, Delivery_location_latitude=12.924264, Delivery_location_longitude=77.6884, Order_Date='19-03-2022', Time_Orderd='08:30:00', Time_Order_picked=datetime.datetime(2023, 8, 19, 8, 45), Weatherconditions='conditions Sandstorms', Road_traffic_density='Low ', Vehicle_condition=0, Type_of_order='Drinks ', Type_of_vehicle='motorcycle ', multiple_deliveries=1.0, Festival='No ', City='Urban ', Time_taken(min)='(min) 26'),\n Row(ID='0x7a6a ', Delivery_person_ID='COIMBRES13DEL02 ', Delivery_person_Age=38.0, Delivery_person_Ratings=4.7, Restaurant_latitude=11.003669, Restaurant_longitude=76.976494, Delivery_location_latitude=11.053669, Delivery_location_longitude=77.026494, Order_Date='05-04-2022', Time_Orderd='18:00:00', Time_Order_picked=datetime.datetime(2023, 8, 19, 18, 10), Weatherconditions='conditions Sunny', Road_traffic_density='Medium ', Vehicle_condition=0, Type_of_order='Buffet ', Type_of_vehicle='motorcycle ', multiple_deliveries=1.0, Festival='No ', City='Metropolitian ', Time_taken(min)='(min) 21'),\n Row(ID='0x70a2 ', Delivery_person_ID='CHENRES12DEL01 ', Delivery_person_Age=32.0, Delivery_person_Ratings=4.6, Restaurant_latitude=12.972793, Restaurant_longitude=80.249982, Delivery_location_latitude=13.012793, Delivery_location_longitude=80.289982, Order_Date='26-03-2022', Time_Orderd='13:30:00', Time_Order_picked=datetime.datetime(2023, 8, 19, 13, 45), Weatherconditions='conditions Cloudy', Road_traffic_density='High ', Vehicle_condition=1, Type_of_order='Snack ', Type_of_vehicle='scooter ', multiple_deliveries=1.0, Festival='No ', City='Metropolitian ', Time_taken(min)='(min) 30')]"},"metadata":{}}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> describe(), summary()","metadata":{}},{"cell_type":"code","source":"## Basic statistics of the data:\ndf.describe()    ### df.summary()\ndf.describe().show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:35.540722Z","iopub.execute_input":"2023-08-19T19:28:35.541418Z","iopub.status.idle":"2023-08-19T19:28:38.426900Z","shell.execute_reply.started":"2023-08-19T19:28:35.541384Z","shell.execute_reply":"2023-08-19T19:28:38.425562Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stderr","text":"[Stage 95:=============================>                            (1 + 1) / 2]\r","output_type":"stream"},{"name":"stdout","text":"+-------+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-----------------+--------------------+------------------+-------------+---------------+-------------------+--------+--------------+---------------+\n|summary|     ID|Delivery_person_ID|Delivery_person_Age|Delivery_person_Ratings|Restaurant_latitude|Restaurant_longitude|Delivery_location_latitude|Delivery_location_longitude|Order_Date|Time_Orderd|Weatherconditions|Road_traffic_density| Vehicle_condition|Type_of_order|Type_of_vehicle|multiple_deliveries|Festival|          City|Time_taken(min)|\n+-------+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-----------------+--------------------+------------------+-------------+---------------+-------------------+--------+--------------+---------------+\n|  count|  45593|             45593|              45593|                  45593|              45593|               45593|                     45593|                      45593|     45593|      45593|            45593|               45593|             45593|        45593|          45593|              45593|   45593|         45593|          45593|\n|   mean|   null|              null|                NaN|                    NaN| 17.017728506525582|   70.23133233807862|        17.465185865088966|          70.84570225567651|      null|        NaN|             null|                 NaN|  1.02335884894611|         null|           null|                NaN|     NaN|           NaN|           null|\n| stddev|   null|              null|                NaN|                    NaN|  8.185108965214452|   22.88364722309305|        7.3351219945143376|         21.118811879085857|      null|        NaN|             null|                 NaN|0.8390647867161859|         null|           null|                NaN|     NaN|           NaN|           null|\n|    min|0x1000 |   AGRRES010DEL01 |               15.0|                    1.0|         -30.905562|          -88.366217|                      0.01|                       0.01|01-03-2022|   00:00:00|conditions Cloudy|               High |                 0|      Buffet |       bicycle |                0.0|    NaN |Metropolitian |       (min) 10|\n|    max| 0xffe |    VADRES20DEL03 |                NaN|                    NaN|          30.914057|           88.433452|                 31.054057|                  88.563452|31-03-2022|       NaN | conditions Windy|                NaN |                 3|       Snack |       scooter |                NaN|    Yes |        Urban |       (min) 54|\n+-------+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-----------------+--------------------+------------------+-------------+---------------+-------------------+--------+--------------+---------------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"#### NOTE: describe() represents the statistical summary of dataframe but it also uses the string variables","metadata":{}},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> count(), columns","metadata":{}},{"cell_type":"code","source":"## Shape of the dataframe is:\ndf.count(),len(df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:38.428185Z","iopub.execute_input":"2023-08-19T19:28:38.428655Z","iopub.status.idle":"2023-08-19T19:28:38.605494Z","shell.execute_reply.started":"2023-08-19T19:28:38.428612Z","shell.execute_reply":"2023-08-19T19:28:38.604280Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"(45593, 20)"},"metadata":{}}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> col(), isNull()","metadata":{}},{"cell_type":"code","source":"## Checking for null values:\ndf.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:38.608284Z","iopub.execute_input":"2023-08-19T19:28:38.609085Z","iopub.status.idle":"2023-08-19T19:28:39.192809Z","shell.execute_reply.started":"2023-08-19T19:28:38.609043Z","shell.execute_reply":"2023-08-19T19:28:39.191587Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"+---+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-----------------+-----------------+--------------------+-----------------+-------------+---------------+-------------------+--------+----+---------------+\n| ID|Delivery_person_ID|Delivery_person_Age|Delivery_person_Ratings|Restaurant_latitude|Restaurant_longitude|Delivery_location_latitude|Delivery_location_longitude|Order_Date|Time_Orderd|Time_Order_picked|Weatherconditions|Road_traffic_density|Vehicle_condition|Type_of_order|Type_of_vehicle|multiple_deliveries|Festival|City|Time_taken(min)|\n+---+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-----------------+-----------------+--------------------+-----------------+-------------+---------------+-------------------+--------+----+---------------+\n|  0|                 0|                  0|                      0|                  0|                   0|                         0|                          0|         0|          0|                0|                0|                   0|                0|            0|              0|                  0|       0|   0|              0|\n+---+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-----------------+-----------------+--------------------+-----------------+-------------+---------------+-------------------+--------+----+---------------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Looks like there are no null values.","metadata":{}},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> dtypes","metadata":{}},{"cell_type":"code","source":"## Checking the dtypes:\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:39.194061Z","iopub.execute_input":"2023-08-19T19:28:39.194502Z","iopub.status.idle":"2023-08-19T19:28:39.210927Z","shell.execute_reply.started":"2023-08-19T19:28:39.194460Z","shell.execute_reply":"2023-08-19T19:28:39.209743Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"[('ID', 'string'),\n ('Delivery_person_ID', 'string'),\n ('Delivery_person_Age', 'double'),\n ('Delivery_person_Ratings', 'double'),\n ('Restaurant_latitude', 'double'),\n ('Restaurant_longitude', 'double'),\n ('Delivery_location_latitude', 'double'),\n ('Delivery_location_longitude', 'double'),\n ('Order_Date', 'string'),\n ('Time_Orderd', 'string'),\n ('Time_Order_picked', 'timestamp'),\n ('Weatherconditions', 'string'),\n ('Road_traffic_density', 'string'),\n ('Vehicle_condition', 'int'),\n ('Type_of_order', 'string'),\n ('Type_of_vehicle', 'string'),\n ('multiple_deliveries', 'double'),\n ('Festival', 'string'),\n ('City', 'string'),\n ('Time_taken(min)', 'string')]"},"metadata":{}}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> select()","metadata":{}},{"cell_type":"code","source":"## To view a few selected columns:\ndf.select([\"ID\",\"Delivery_person_ID\"]).show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:39.213088Z","iopub.execute_input":"2023-08-19T19:28:39.213563Z","iopub.status.idle":"2023-08-19T19:28:39.292987Z","shell.execute_reply.started":"2023-08-19T19:28:39.213520Z","shell.execute_reply":"2023-08-19T19:28:39.291842Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"+-------+------------------+\n|     ID|Delivery_person_ID|\n+-------+------------------+\n|0x4607 |   INDORES13DEL02 |\n|0xb379 |   BANGRES18DEL02 |\n|0x5d6d |   BANGRES19DEL01 |\n|0x7a6a |  COIMBRES13DEL02 |\n|0x70a2 |   CHENRES12DEL01 |\n|0x9bb4 |    HYDRES09DEL03 |\n|0x95b4 | RANCHIRES15DEL01 |\n|0x9eb2 |    MYSRES15DEL02 |\n|0x1102 |    HYDRES05DEL02 |\n|0xcdcd |    DEHRES17DEL01 |\n|0xd987 |    KOCRES16DEL01 |\n|0x2784 |   PUNERES13DEL03 |\n|0xc8b6 |   LUDHRES15DEL02 |\n|0xdb64 |    KNPRES14DEL02 |\n|0x3af3 |    MUMRES15DEL03 |\n|0x3aab |    MYSRES01DEL01 |\n|0x689b |   PUNERES20DEL01 |\n|0x6f67 |    HYDRES14DEL01 |\n|0xc9cf |    KOLRES15DEL03 |\n|0x36b8 |   PUNERES19DEL02 |\n+-------+------------------+\nonly showing top 20 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df.printSchema()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:39.294238Z","iopub.execute_input":"2023-08-19T19:28:39.294893Z","iopub.status.idle":"2023-08-19T19:28:39.303251Z","shell.execute_reply.started":"2023-08-19T19:28:39.294850Z","shell.execute_reply":"2023-08-19T19:28:39.302444Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"root\n |-- ID: string (nullable = true)\n |-- Delivery_person_ID: string (nullable = true)\n |-- Delivery_person_Age: double (nullable = true)\n |-- Delivery_person_Ratings: double (nullable = true)\n |-- Restaurant_latitude: double (nullable = true)\n |-- Restaurant_longitude: double (nullable = true)\n |-- Delivery_location_latitude: double (nullable = true)\n |-- Delivery_location_longitude: double (nullable = true)\n |-- Order_Date: string (nullable = true)\n |-- Time_Orderd: string (nullable = true)\n |-- Time_Order_picked: timestamp (nullable = true)\n |-- Weatherconditions: string (nullable = true)\n |-- Road_traffic_density: string (nullable = true)\n |-- Vehicle_condition: integer (nullable = true)\n |-- Type_of_order: string (nullable = true)\n |-- Type_of_vehicle: string (nullable = true)\n |-- multiple_deliveries: double (nullable = true)\n |-- Festival: string (nullable = true)\n |-- City: string (nullable = true)\n |-- Time_taken(min): string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> cast()","metadata":{}},{"cell_type":"markdown","source":"#### The various datatypes that a column can take up are integers, string, double, float, timestamp, etc...\n\n#### To convert a column into:\n\n1. double ---> use DoubleType()\n\n2. int    ---> use IntegerType()\n\n3. float  ---> use FloatType()\n\n4. string ---> use StringType()\n\n5. long   ---> use LongType()\n\n#### all inside the cast() method.","metadata":{}},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> withColumn()\n\n#### In PySpark, the withColumn() function is widely used and defined as the **transformation function** of the DataFrame\n\n#### which is further\n\n- used to change the value, \n\n- convert the datatype of an existing column, \n\n- create the new column etc...","metadata":{}},{"cell_type":"code","source":"## Have to correct the datatypes of some columns. Delivery_person_Age, Vehicle_condition, multiple_deliveries\ndf=df.withColumn('Delivery_person_Age',col('Delivery_person_Age').cast(IntegerType()))\\\n.withColumn('Vehicle_condition',col('Vehicle_condition').cast(IntegerType()))\\\n.withColumn('multiple_deliveries',col('multiple_deliveries').cast(IntegerType()))","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:39.304608Z","iopub.execute_input":"2023-08-19T19:28:39.305169Z","iopub.status.idle":"2023-08-19T19:28:39.367506Z","shell.execute_reply.started":"2023-08-19T19:28:39.305138Z","shell.execute_reply":"2023-08-19T19:28:39.366330Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"## Checking after conversion:\ndf.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:39.368977Z","iopub.execute_input":"2023-08-19T19:28:39.369359Z","iopub.status.idle":"2023-08-19T19:28:39.378531Z","shell.execute_reply.started":"2023-08-19T19:28:39.369327Z","shell.execute_reply":"2023-08-19T19:28:39.377473Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"[('ID', 'string'),\n ('Delivery_person_ID', 'string'),\n ('Delivery_person_Age', 'int'),\n ('Delivery_person_Ratings', 'double'),\n ('Restaurant_latitude', 'double'),\n ('Restaurant_longitude', 'double'),\n ('Delivery_location_latitude', 'double'),\n ('Delivery_location_longitude', 'double'),\n ('Order_Date', 'string'),\n ('Time_Orderd', 'string'),\n ('Time_Order_picked', 'timestamp'),\n ('Weatherconditions', 'string'),\n ('Road_traffic_density', 'string'),\n ('Vehicle_condition', 'int'),\n ('Type_of_order', 'string'),\n ('Type_of_vehicle', 'string'),\n ('multiple_deliveries', 'int'),\n ('Festival', 'string'),\n ('City', 'string'),\n ('Time_taken(min)', 'string')]"},"metadata":{}}]},{"cell_type":"code","source":"df.select(['Delivery_person_Age','Vehicle_condition','multiple_deliveries']).dtypes","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:39.380409Z","iopub.execute_input":"2023-08-19T19:28:39.381659Z","iopub.status.idle":"2023-08-19T19:28:39.403833Z","shell.execute_reply.started":"2023-08-19T19:28:39.381616Z","shell.execute_reply":"2023-08-19T19:28:39.402661Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"[('Delivery_person_Age', 'int'),\n ('Vehicle_condition', 'int'),\n ('multiple_deliveries', 'int')]"},"metadata":{}}]},{"cell_type":"code","source":"## To display the PySpark dataframe as a pandas dataframe:\ndf.toPandas().head()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:39.405739Z","iopub.execute_input":"2023-08-19T19:28:39.406536Z","iopub.status.idle":"2023-08-19T19:28:42.537222Z","shell.execute_reply.started":"2023-08-19T19:28:39.406493Z","shell.execute_reply":"2023-08-19T19:28:42.536212Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"        ID Delivery_person_ID  Delivery_person_Age  Delivery_person_Ratings  \\\n0  0x4607     INDORES13DEL02                    37                      4.9   \n1  0xb379     BANGRES18DEL02                    34                      4.5   \n2  0x5d6d     BANGRES19DEL01                    23                      4.4   \n3  0x7a6a    COIMBRES13DEL02                    38                      4.7   \n4  0x70a2     CHENRES12DEL01                    32                      4.6   \n\n   Restaurant_latitude  Restaurant_longitude  Delivery_location_latitude  \\\n0            22.745049             75.892471                   22.765049   \n1            12.913041             77.683237                   13.043041   \n2            12.914264             77.678400                   12.924264   \n3            11.003669             76.976494                   11.053669   \n4            12.972793             80.249982                   13.012793   \n\n   Delivery_location_longitude  Order_Date Time_Orderd   Time_Order_picked  \\\n0                    75.912471  19-03-2022    11:30:00 2023-08-19 11:45:00   \n1                    77.813237  25-03-2022    19:45:00 2023-08-19 19:50:00   \n2                    77.688400  19-03-2022    08:30:00 2023-08-19 08:45:00   \n3                    77.026494  05-04-2022    18:00:00 2023-08-19 18:10:00   \n4                    80.289982  26-03-2022    13:30:00 2023-08-19 13:45:00   \n\n       Weatherconditions Road_traffic_density  Vehicle_condition  \\\n0       conditions Sunny                High                   2   \n1      conditions Stormy                 Jam                   2   \n2  conditions Sandstorms                 Low                   0   \n3       conditions Sunny              Medium                   0   \n4      conditions Cloudy                High                   1   \n\n  Type_of_order Type_of_vehicle  multiple_deliveries Festival            City  \\\n0        Snack      motorcycle                     0      No           Urban    \n1        Snack         scooter                     1      No   Metropolitian    \n2       Drinks      motorcycle                     1      No           Urban    \n3       Buffet      motorcycle                     1      No   Metropolitian    \n4        Snack         scooter                     1      No   Metropolitian    \n\n  Time_taken(min)  \n0        (min) 24  \n1        (min) 33  \n2        (min) 26  \n3        (min) 21  \n4        (min) 30  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Delivery_person_ID</th>\n      <th>Delivery_person_Age</th>\n      <th>Delivery_person_Ratings</th>\n      <th>Restaurant_latitude</th>\n      <th>Restaurant_longitude</th>\n      <th>Delivery_location_latitude</th>\n      <th>Delivery_location_longitude</th>\n      <th>Order_Date</th>\n      <th>Time_Orderd</th>\n      <th>Time_Order_picked</th>\n      <th>Weatherconditions</th>\n      <th>Road_traffic_density</th>\n      <th>Vehicle_condition</th>\n      <th>Type_of_order</th>\n      <th>Type_of_vehicle</th>\n      <th>multiple_deliveries</th>\n      <th>Festival</th>\n      <th>City</th>\n      <th>Time_taken(min)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0x4607</td>\n      <td>INDORES13DEL02</td>\n      <td>37</td>\n      <td>4.9</td>\n      <td>22.745049</td>\n      <td>75.892471</td>\n      <td>22.765049</td>\n      <td>75.912471</td>\n      <td>19-03-2022</td>\n      <td>11:30:00</td>\n      <td>2023-08-19 11:45:00</td>\n      <td>conditions Sunny</td>\n      <td>High</td>\n      <td>2</td>\n      <td>Snack</td>\n      <td>motorcycle</td>\n      <td>0</td>\n      <td>No</td>\n      <td>Urban</td>\n      <td>(min) 24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0xb379</td>\n      <td>BANGRES18DEL02</td>\n      <td>34</td>\n      <td>4.5</td>\n      <td>12.913041</td>\n      <td>77.683237</td>\n      <td>13.043041</td>\n      <td>77.813237</td>\n      <td>25-03-2022</td>\n      <td>19:45:00</td>\n      <td>2023-08-19 19:50:00</td>\n      <td>conditions Stormy</td>\n      <td>Jam</td>\n      <td>2</td>\n      <td>Snack</td>\n      <td>scooter</td>\n      <td>1</td>\n      <td>No</td>\n      <td>Metropolitian</td>\n      <td>(min) 33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0x5d6d</td>\n      <td>BANGRES19DEL01</td>\n      <td>23</td>\n      <td>4.4</td>\n      <td>12.914264</td>\n      <td>77.678400</td>\n      <td>12.924264</td>\n      <td>77.688400</td>\n      <td>19-03-2022</td>\n      <td>08:30:00</td>\n      <td>2023-08-19 08:45:00</td>\n      <td>conditions Sandstorms</td>\n      <td>Low</td>\n      <td>0</td>\n      <td>Drinks</td>\n      <td>motorcycle</td>\n      <td>1</td>\n      <td>No</td>\n      <td>Urban</td>\n      <td>(min) 26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0x7a6a</td>\n      <td>COIMBRES13DEL02</td>\n      <td>38</td>\n      <td>4.7</td>\n      <td>11.003669</td>\n      <td>76.976494</td>\n      <td>11.053669</td>\n      <td>77.026494</td>\n      <td>05-04-2022</td>\n      <td>18:00:00</td>\n      <td>2023-08-19 18:10:00</td>\n      <td>conditions Sunny</td>\n      <td>Medium</td>\n      <td>0</td>\n      <td>Buffet</td>\n      <td>motorcycle</td>\n      <td>1</td>\n      <td>No</td>\n      <td>Metropolitian</td>\n      <td>(min) 21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x70a2</td>\n      <td>CHENRES12DEL01</td>\n      <td>32</td>\n      <td>4.6</td>\n      <td>12.972793</td>\n      <td>80.249982</td>\n      <td>13.012793</td>\n      <td>80.289982</td>\n      <td>26-03-2022</td>\n      <td>13:30:00</td>\n      <td>2023-08-19 13:45:00</td>\n      <td>conditions Cloudy</td>\n      <td>High</td>\n      <td>1</td>\n      <td>Snack</td>\n      <td>scooter</td>\n      <td>1</td>\n      <td>No</td>\n      <td>Metropolitian</td>\n      <td>(min) 30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"## Checking the numeric columns:\ndef num_cols(dataframe):\n    num_cols = [col for col in dataframe.columns if dataframe.select(col).dtypes[0][1] in ['double', 'int']]\n    return num_cols\n\nnum_cols = num_cols(df)  ### list of numeric columns\n    \ndf.describe(num_cols).show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:42.538708Z","iopub.execute_input":"2023-08-19T19:28:42.539794Z","iopub.status.idle":"2023-08-19T19:28:43.494603Z","shell.execute_reply.started":"2023-08-19T19:28:42.539752Z","shell.execute_reply":"2023-08-19T19:28:43.493705Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"+-------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+------------------+-------------------+\n|summary|Delivery_person_Age|Delivery_person_Ratings|Restaurant_latitude|Restaurant_longitude|Delivery_location_latitude|Delivery_location_longitude| Vehicle_condition|multiple_deliveries|\n+-------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+------------------+-------------------+\n|  count|              45593|                  45593|              45593|               45593|                     45593|                      45593|             45593|              45593|\n|   mean| 28.364814774197793|                    NaN| 17.017728506525582|   70.23133233807862|        17.465185865088966|          70.84570225567651|  1.02335884894611| 0.7284451560546575|\n| stddev|  8.157529884739837|                    NaN|  8.185108965214452|   22.88364722309305|        7.3351219945143376|         21.118811879085857|0.8390647867161859| 0.5765432892259538|\n|    min|                  0|                    1.0|         -30.905562|          -88.366217|                      0.01|                       0.01|                 0|                  0|\n|    max|                 50|                    NaN|          30.914057|           88.433452|                 31.054057|                  88.563452|                 3|                  3|\n+-------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+------------------+-------------------+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> distinct()","metadata":{}},{"cell_type":"code","source":"### There are 1320 unique IDs\ndf.select('Delivery_person_ID').distinct().count()  ","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:43.495568Z","iopub.execute_input":"2023-08-19T19:28:43.495904Z","iopub.status.idle":"2023-08-19T19:28:43.968628Z","shell.execute_reply.started":"2023-08-19T19:28:43.495876Z","shell.execute_reply":"2023-08-19T19:28:43.967774Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"1320"},"metadata":{}}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> orderBy()","metadata":{}},{"cell_type":"code","source":"### Counts of unique delivery person ids::\ndf.select('Delivery_person_ID').distinct().show()  ### 20 \ndf.groupBy('Delivery_person_ID').count().orderBy('count').show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:43.969532Z","iopub.execute_input":"2023-08-19T19:28:43.969811Z","iopub.status.idle":"2023-08-19T19:28:44.661555Z","shell.execute_reply.started":"2023-08-19T19:28:43.969786Z","shell.execute_reply":"2023-08-19T19:28:44.660352Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"+------------------+\n|Delivery_person_ID|\n+------------------+\n|    SURRES11DEL01 |\n|    GOARES02DEL01 |\n|    KNPRES09DEL03 |\n|    KOCRES02DEL01 |\n|    KOLRES08DEL01 |\n|    BHPRES13DEL03 |\n|    ALHRES06DEL02 |\n|    BHPRES05DEL02 |\n|    GOARES03DEL03 |\n|    VADRES16DEL02 |\n|    VADRES04DEL02 |\n|  COIMBRES07DEL01 |\n|    KNPRES08DEL03 |\n|   LUDHRES09DEL01 |\n|    KOCRES09DEL01 |\n|   MUMRES010DEL02 |\n| RANCHIRES11DEL01 |\n|    HYDRES09DEL02 |\n|    DEHRES06DEL02 |\n|    BHPRES09DEL03 |\n+------------------+\nonly showing top 20 rows\n\n+------------------+-----+\n|Delivery_person_ID|count|\n+------------------+-----+\n|   BHPRES010DEL03 |    5|\n|    KOLRES09DEL03 |    6|\n|    KOCRES16DEL03 |    6|\n|    BHPRES15DEL03 |    7|\n|   AURGRES13DEL03 |    7|\n|    GOARES01DEL03 |    7|\n|   AURGRES11DEL03 |    7|\n|    DEHRES18DEL03 |    7|\n|   LUDHRES01DEL03 |    8|\n|    GOARES11DEL01 |    8|\n|    KOLRES08DEL03 |    8|\n|    BHPRES06DEL03 |    8|\n|   AURGRES06DEL03 |    8|\n|   GOARES010DEL03 |    8|\n|    BHPRES11DEL03 |    8|\n|    GOARES19DEL03 |    8|\n|    AGRRES11DEL02 |    8|\n|    GOARES13DEL03 |    8|\n|    GOARES05DEL03 |    8|\n|    BHPRES09DEL03 |    8|\n+------------------+-----+\nonly showing top 20 rows\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h2><div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:#5642C5;\n           font-size:110%;\n           font-family:Verdana;\n           letter-spacing:0.5px\">\n        <p style=\"padding: 10px;\n              color:white;\">\n            Feature Engineering Overview\n        </p>\n    </div></h2>","metadata":{}},{"cell_type":"markdown","source":"As observed from the above dataset, we can extract the following:\n\n1. City from Delivery_person_ID ----> city  âœ…\n\n2. Bucket cities into Zones - North, South, East, West  ----> city_zone  âœ…\n\n3. Cleaning the Weatherconditions column\n\n4. Time taken to pick up delivery using Time_Orderd and Time_Order_picked ----> pickup_time\n\n5. Time of the day - Morning, Lunch, Evening, Night, Midnight ----> day_zone\n\n6. To clean up target variable - Time_taken(min)  âœ…\n\n7. Bucket Age - Delivery_person_Age ----> life_stage\n\n8. Features using Latitude and Longitude ----> geosidic\n\n9. Handle NaN values in all column","metadata":{}},{"cell_type":"markdown","source":"<blockquote><p style=\"font-size:20px; color:#159364; font-family:verdana;\">1. City from delivery id:</p></blockquote>\n\n### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> udf()\n\n#### In order to apply a function into a particular column, we have create the function and register it as a UDF(User Defined Function) on Spark.\n\n#### It is imported from the pyspark.sql.functions module.","metadata":{}},{"cell_type":"code","source":"# Create custom function\ndef city_extract(x):\n    return re.findall(\"(\\S+)RES\\S+\",x)[0]\n\n# Convert the function as a UDF using the udf function:\ncity_extract_UDF = udf(lambda x:city_extract(x),StringType()) \n\n# Apply the function on the desired column:\ndf=df.withColumn(\"City\",city_extract_UDF(col(\"Delivery_person_ID\")))\n\n## Having a glance at the new column:\ndf.select(['Delivery_person_ID','City']).show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:44.662843Z","iopub.execute_input":"2023-08-19T19:28:44.663289Z","iopub.status.idle":"2023-08-19T19:28:45.032746Z","shell.execute_reply.started":"2023-08-19T19:28:44.663221Z","shell.execute_reply":"2023-08-19T19:28:45.031538Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"+------------------+------+\n|Delivery_person_ID|  City|\n+------------------+------+\n|   INDORES13DEL02 |  INDO|\n|   BANGRES18DEL02 |  BANG|\n|   BANGRES19DEL01 |  BANG|\n|  COIMBRES13DEL02 | COIMB|\n|   CHENRES12DEL01 |  CHEN|\n|    HYDRES09DEL03 |   HYD|\n| RANCHIRES15DEL01 |RANCHI|\n|    MYSRES15DEL02 |   MYS|\n|    HYDRES05DEL02 |   HYD|\n|    DEHRES17DEL01 |   DEH|\n|    KOCRES16DEL01 |   KOC|\n|   PUNERES13DEL03 |  PUNE|\n|   LUDHRES15DEL02 |  LUDH|\n|    KNPRES14DEL02 |   KNP|\n|    MUMRES15DEL03 |   MUM|\n|    MYSRES01DEL01 |   MYS|\n|   PUNERES20DEL01 |  PUNE|\n|    HYDRES14DEL01 |   HYD|\n|    KOLRES15DEL03 |   KOL|\n|   PUNERES19DEL02 |  PUNE|\n+------------------+------+\nonly showing top 20 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df.select(\"City\").distinct().show(22)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:45.034021Z","iopub.execute_input":"2023-08-19T19:28:45.034451Z","iopub.status.idle":"2023-08-19T19:28:46.021881Z","shell.execute_reply.started":"2023-08-19T19:28:45.034412Z","shell.execute_reply":"2023-08-19T19:28:46.020810Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stderr","text":"[Stage 122:>                                                        (0 + 2) / 2]\r","output_type":"stream"},{"name":"stdout","text":"+------+\n|  City|\n+------+\n|  LUDH|\n|  CHEN|\n|   KOC|\n|   GOA|\n|  AURG|\n|   JAP|\n|   DEH|\n|   MUM|\n|   AGR|\n|   SUR|\n|  INDO|\n|  PUNE|\n|   ALH|\n|   MYS|\n| COIMB|\n|   HYD|\n|   VAD|\n|RANCHI|\n|   BHP|\n|   KOL|\n|   KNP|\n|  BANG|\n+------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> groupBy(), sort()--asc()/desc()","metadata":{}},{"cell_type":"code","source":"## To get count of the distinct cities:: (equivalent to value_counts() method in pandas)\ndf.groupBy(\"City\").count().sort(col(\"count\").desc()).show(22)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:46.023131Z","iopub.execute_input":"2023-08-19T19:28:46.023545Z","iopub.status.idle":"2023-08-19T19:28:46.990797Z","shell.execute_reply.started":"2023-08-19T19:28:46.023507Z","shell.execute_reply":"2023-08-19T19:28:46.989675Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stderr","text":"[Stage 125:>                                                        (0 + 2) / 2]\r","output_type":"stream"},{"name":"stdout","text":"+------+-----+\n|  City|count|\n+------+-----+\n|   JAP| 3443|\n|RANCHI| 3229|\n|  BANG| 3195|\n|   SUR| 3187|\n|   HYD| 3181|\n|   MUM| 3173|\n|   MYS| 3171|\n| COIMB| 3170|\n|   VAD| 3166|\n|  INDO| 3159|\n|  CHEN| 3145|\n|  PUNE| 3132|\n|   AGR|  763|\n|  LUDH|  758|\n|   ALH|  740|\n|   KNP|  740|\n|   DEH|  737|\n|   GOA|  709|\n|  AURG|  703|\n|   KOC|  701|\n|   KOL|  700|\n|   BHP|  691|\n+------+-----+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> rdd.flatMap().collect()\n\nMethods to convert a pyspark column into a list/array:","metadata":{}},{"cell_type":"code","source":"df.select(\"City\").distinct().rdd.flatMap(lambda x: x).collect()  ### to convert a column into a list\ndf.select(\"City\").distinct().toPandas().values.flatten()  ### to convert a column into a numpy array","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:46.992033Z","iopub.execute_input":"2023-08-19T19:28:46.992794Z","iopub.status.idle":"2023-08-19T19:28:49.092528Z","shell.execute_reply.started":"2023-08-19T19:28:46.992753Z","shell.execute_reply":"2023-08-19T19:28:49.091612Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"},{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"array(['LUDH', 'CHEN', 'KOC', 'GOA', 'AURG', 'JAP', 'DEH', 'MUM', 'AGR',\n       'SUR', 'INDO', 'PUNE', 'ALH', 'MYS', 'COIMB', 'HYD', 'VAD',\n       'RANCHI', 'BHP', 'KOL', 'KNP', 'BANG'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"### <span style=\"background-color: #00FF00;font-size: 35px\">ðŸŒ¼</span> withColumnRenamed()\n\n#### Use withColumnRenamed method to rename a column.","metadata":{}},{"cell_type":"code","source":"## Renaming the column to avoid name clash:\ndf=df.withColumnRenamed(\"City\",\"City_encodings\")","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:49.093969Z","iopub.execute_input":"2023-08-19T19:28:49.094380Z","iopub.status.idle":"2023-08-19T19:28:49.105788Z","shell.execute_reply.started":"2023-08-19T19:28:49.094348Z","shell.execute_reply":"2023-08-19T19:28:49.104540Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"## Checking to see if change has reflected:\ndf.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:49.113078Z","iopub.execute_input":"2023-08-19T19:28:49.114614Z","iopub.status.idle":"2023-08-19T19:28:49.124251Z","shell.execute_reply.started":"2023-08-19T19:28:49.114551Z","shell.execute_reply":"2023-08-19T19:28:49.123232Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"['ID',\n 'Delivery_person_ID',\n 'Delivery_person_Age',\n 'Delivery_person_Ratings',\n 'Restaurant_latitude',\n 'Restaurant_longitude',\n 'Delivery_location_latitude',\n 'Delivery_location_longitude',\n 'Order_Date',\n 'Time_Orderd',\n 'Time_Order_picked',\n 'Weatherconditions',\n 'Road_traffic_density',\n 'Vehicle_condition',\n 'Type_of_order',\n 'Type_of_vehicle',\n 'multiple_deliveries',\n 'Festival',\n 'City_encodings',\n 'Time_taken(min)']"},"metadata":{}}]},{"cell_type":"code","source":"### Created a manual list of the full form of the city encodings:\ndic_city={\"LUDH\":\"Ludhiana\",\n\"CHEN\":\"Chennai\",\n\"KOC\":\"Kochi\",\n\"GOA\":\"Goa\",\n\"AURG\":\"Aurangabad\",\n\"JAP\":\"Jaipur\",\n\"DEH\":\"Delhi\",\n\"MUM\":\"Mumbai\",\n\"AGR\":\"Agra\",\n\"SUR\":\"Surat\",\n\"INDO\":\"Indore\",\n\"PUNE\":\"Pune\",\n\"ALH\":\"Allahabad\",\n\"MYS\":\"Mysore\",\n\"COIMB\":\"Coimbatore\",\n\"HYD\":\"Hyderabad\",\n\"VAD\":\"Vadodara\",\n\"RANCHI\":\"Ranchi\",\n\"BHP\":\"Bhopal\",\n\"KOL\":\"Kolkatta\",\n\"KNP\":\"Kanpur\",\n\"BANG\":\"Bangalore\"}","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:28:49.126590Z","iopub.execute_input":"2023-08-19T19:28:49.127523Z","iopub.status.idle":"2023-08-19T19:28:49.136111Z","shell.execute_reply.started":"2023-08-19T19:28:49.127478Z","shell.execute_reply":"2023-08-19T19:28:49.134747Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"NOTE: You cannot pass dictionaries as a parameter for a UDF! Hence the below code cell will raise an error:","metadata":{}},{"cell_type":"code","source":"## Creating a udf to map the encodings with their original names:\ndef city_map(x,dic):\n    return dic[x['City_encodings']]\nudf_city_map=udf(lambda x:city_map(x,dic),StringType())\ndf=df.withColumn(\"City\",udf_city_map(col(\"City_encodings\")))","metadata":{"execution":{"iopub.status.busy":"2023-08-19T12:08:51.157057Z","iopub.execute_input":"2023-08-19T12:08:51.157453Z","iopub.status.idle":"2023-08-19T12:08:51.193723Z","shell.execute_reply.started":"2023-08-19T12:08:51.157422Z","shell.execute_reply":"2023-08-19T12:08:51.192453Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hence you have to make a small change in the way you define the function by creating a nested function for indirectly passing the dictionary as a parameter to the UDF:","metadata":{}},{"cell_type":"code","source":"def get_city(mapping):\n    def f(x):\n        return mapping.get(x)\n    return udf(f)\n\ndf=df.withColumn('City', get_city(dic_city)(col('City_encodings')))","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:47:06.543059Z","iopub.execute_input":"2023-08-19T19:47:06.543477Z","iopub.status.idle":"2023-08-19T19:47:06.573414Z","shell.execute_reply.started":"2023-08-19T19:47:06.543444Z","shell.execute_reply":"2023-08-19T19:47:06.572374Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"## Checking the dataset for the new column:\ndf.select(\"City\").show(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:46:04.510014Z","iopub.execute_input":"2023-08-19T19:46:04.510444Z","iopub.status.idle":"2023-08-19T19:46:04.870484Z","shell.execute_reply.started":"2023-08-19T19:46:04.510407Z","shell.execute_reply":"2023-08-19T19:46:04.869233Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"+----------+\n|      City|\n+----------+\n|    Indore|\n| Bangalore|\n| Bangalore|\n|Coimbatore|\n|   Chennai|\n+----------+\nonly showing top 5 rows\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<blockquote><p style=\"font-size:20px; color:#159364; font-family:verdana;\">2. Bucketing cities into various Zones - North, South, East, West:</p></blockquote>","metadata":{}},{"cell_type":"code","source":"## NOTE: THIS IS COMPLETELY BASED ON MY INTUTION, PLZ CORRECT THIS, IF THERE ANY MISTAKES, IN YOUR OWN ANALYSIS:\ndic_zones={\"Ludhiana\":\"North\",\n\"Chennai\":\"South\",\n\"Kochi\":\"South\",\n\"Goa\":\"West\",\n\"Aurangabad\":\"West\",\n\"Jaipur\":\"North\",\n\"Delhi\":\"North\",\n\"Mumbai\":\"West\",\n\"Agra\":\"North\",\n\"Surat\":\"East\",\n\"Indore\":\"Central\",\n\"Pune\":\"West\",\n\"Allahabad\":\"North\",\n\"Mysore\":\"South\",\n\"Coimbatore\":\"South\",\n\"Hyderabad\":\"South\",\n\"Vadodara\":\"West\",\n\"Ranchi\":\"North\",\n\"Bhopal\":\"North\",\n\"Kolkatta\":\"East\",\n\"Kanpur\":\"North\",\n\"Bangalore\":\"South\"}","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:46:49.996379Z","iopub.execute_input":"2023-08-19T19:46:49.996796Z","iopub.status.idle":"2023-08-19T19:46:50.004368Z","shell.execute_reply.started":"2023-08-19T19:46:49.996766Z","shell.execute_reply":"2023-08-19T19:46:50.003342Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"def get_zone(mapping):\n    def f(x):\n        return mapping.get(x)\n    return udf(f)\n\ndf=df.withColumn('city_zone', get_zone(dic_zones)(col('City')))","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:47:18.347010Z","iopub.execute_input":"2023-08-19T19:47:18.347506Z","iopub.status.idle":"2023-08-19T19:47:18.379801Z","shell.execute_reply.started":"2023-08-19T19:47:18.347467Z","shell.execute_reply":"2023-08-19T19:47:18.378595Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"## Checking the new columns:\ndf.select([\"City\",\"city_zone\"]).show(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:47:47.606451Z","iopub.execute_input":"2023-08-19T19:47:47.606863Z","iopub.status.idle":"2023-08-19T19:47:48.072533Z","shell.execute_reply.started":"2023-08-19T19:47:47.606833Z","shell.execute_reply":"2023-08-19T19:47:48.071076Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"+----------+---------+\n|      City|city_zone|\n+----------+---------+\n|    Indore|  Central|\n| Bangalore|    South|\n| Bangalore|    South|\n|Coimbatore|    South|\n|   Chennai|    South|\n+----------+---------+\nonly showing top 5 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<blockquote><p style=\"font-size:20px; color:#159364; font-family:verdana;\">3. Cleaning the Weatherconditions column:</p></blockquote>","metadata":{}},{"cell_type":"code","source":"df.select(\"Weatherconditions\").show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:50:49.921306Z","iopub.execute_input":"2023-08-19T19:50:49.921777Z","iopub.status.idle":"2023-08-19T19:50:50.020740Z","shell.execute_reply.started":"2023-08-19T19:50:49.921742Z","shell.execute_reply":"2023-08-19T19:50:50.019780Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stdout","text":"+--------------------+\n|   Weatherconditions|\n+--------------------+\n|    conditions Sunny|\n|   conditions Stormy|\n|conditions Sandst...|\n|    conditions Sunny|\n|   conditions Cloudy|\n|   conditions Cloudy|\n|      conditions Fog|\n|   conditions Cloudy|\n|   conditions Stormy|\n|      conditions Fog|\n|   conditions Stormy|\n|conditions Sandst...|\n|conditions Sandst...|\n|      conditions Fog|\n|conditions Sandst...|\n|    conditions Windy|\n|conditions Sandst...|\n|   conditions Cloudy|\n|    conditions Windy|\n|conditions Sandst...|\n+--------------------+\nonly showing top 20 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df.groupBy(\"Weatherconditions\").count().sort(col(\"count\").desc()).show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T19:50:50.155882Z","iopub.execute_input":"2023-08-19T19:50:50.156285Z","iopub.status.idle":"2023-08-19T19:50:50.580310Z","shell.execute_reply.started":"2023-08-19T19:50:50.156237Z","shell.execute_reply":"2023-08-19T19:50:50.579076Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stdout","text":"+--------------------+-----+\n|   Weatherconditions|count|\n+--------------------+-----+\n|      conditions Fog| 7654|\n|   conditions Stormy| 7586|\n|   conditions Cloudy| 7536|\n|conditions Sandst...| 7495|\n|    conditions Windy| 7422|\n|    conditions Sunny| 7284|\n|      conditions NaN|  616|\n+--------------------+-----+\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Looks like there are NaN conditions as well. We will have to clean those 616 data points.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<blockquote><p style=\"font-size:20px; color:#159364; font-family:verdana;\">4. Getting Pickup time:</p></blockquote>","metadata":{}},{"cell_type":"code","source":"## equivalent value counts in python:\n## Looks like there are ~1700 rows of null values in this column.\ndf.groupBy('Time_Orderd').count().sort(col(\"count\").desc()).show(10)\n# df.groupBy('Time_Orderd').count().sort(col(\"count\").desc()).select(\"Time_Orderd\").show(1)  ### To view the NaN string","metadata":{"execution":{"iopub.status.busy":"2023-08-19T11:04:25.384905Z","iopub.execute_input":"2023-08-19T11:04:25.385370Z","iopub.status.idle":"2023-08-19T11:04:25.758240Z","shell.execute_reply.started":"2023-08-19T11:04:25.385336Z","shell.execute_reply":"2023-08-19T11:04:25.757026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.select(df['Order_Date']==\"NaN \").count()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T11:03:17.680739Z","iopub.execute_input":"2023-08-19T11:03:17.681255Z","iopub.status.idle":"2023-08-19T11:03:17.895289Z","shell.execute_reply.started":"2023-08-19T11:03:17.681217Z","shell.execute_reply":"2023-08-19T11:03:17.894012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.filter(df['Time_Orderd']==\"NaN \").show()#.select(['Time_Orderd']).show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T11:06:54.318031Z","iopub.execute_input":"2023-08-19T11:06:54.318484Z","iopub.status.idle":"2023-08-19T11:06:54.805375Z","shell.execute_reply.started":"2023-08-19T11:06:54.318452Z","shell.execute_reply":"2023-08-19T11:06:54.804170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.select(['Order_Date','Time_Orderd']).show()\n\ndef funct_combine(x):\n    return x['Order_Date']+\" \"+x['Time_Orderd']","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:59:40.406071Z","iopub.execute_input":"2023-08-19T10:59:40.406539Z","iopub.status.idle":"2023-08-19T10:59:40.508678Z","shell.execute_reply.started":"2023-08-19T10:59:40.406501Z","shell.execute_reply":"2023-08-19T10:59:40.507421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupBy('Time_Order_picked').count().sort(col(\"count\").desc()).show(10)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:41:15.896961Z","iopub.execute_input":"2023-08-19T10:41:15.897438Z","iopub.status.idle":"2023-08-19T10:41:16.458374Z","shell.execute_reply.started":"2023-08-19T10:41:15.897395Z","shell.execute_reply":"2023-08-19T10:41:16.457208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see there are NaN values in the 'Time_Orderd' attribute. We cannot calculate delivery time with NaNs in this column. How do we tackle this. ANY IDEAS?? Let me know your ideas in the comments.","metadata":{}},{"cell_type":"markdown","source":"### <span style=\"background-color: #F3FF00;font-size: 35px\">ðŸ“Œ</span>A go-to approach will be to calculate average pickup time using other non null rows and then imputing the null rows with the average obtained.","metadata":{}},{"cell_type":"code","source":"df.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:41:30.551370Z","iopub.execute_input":"2023-08-19T10:41:30.551757Z","iopub.status.idle":"2023-08-19T10:41:30.988648Z","shell.execute_reply.started":"2023-08-19T10:41:30.551726Z","shell.execute_reply":"2023-08-19T10:41:30.987434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.select(\"Time_Orderd\").show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:57:57.748318Z","iopub.execute_input":"2023-08-19T10:57:57.748726Z","iopub.status.idle":"2023-08-19T10:57:57.846356Z","shell.execute_reply.started":"2023-08-19T10:57:57.748696Z","shell.execute_reply":"2023-08-19T10:57:57.845247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.filter(df[\"Time_Orderd\"]!=\"NaN \").select([\"Time_Orderd\",\"Time_Order_picked\"]).show()","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:57:35.615968Z","iopub.execute_input":"2023-08-19T10:57:35.616378Z","iopub.status.idle":"2023-08-19T10:57:35.748069Z","shell.execute_reply.started":"2023-08-19T10:57:35.616348Z","shell.execute_reply":"2023-08-19T10:57:35.746826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupBy('Time_Orderd').count().sort(col(\"count\").desc()).select(\"Time_Orderd\").show(1)","metadata":{"execution":{"iopub.status.busy":"2023-08-19T10:55:25.287264Z","iopub.execute_input":"2023-08-19T10:55:25.287665Z","iopub.status.idle":"2023-08-19T10:55:25.696245Z","shell.execute_reply.started":"2023-08-19T10:55:25.287636Z","shell.execute_reply":"2023-08-19T10:55:25.694990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<blockquote><p style=\"font-size:20px; color:#159364; font-family:verdana;\">5. Splitting the time of ordering into zones of a day - Morning, Lunch, Evening, Night, Midnight:</p></blockquote>","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-19T20:10:43.170522Z","iopub.execute_input":"2023-08-19T20:10:43.171033Z","iopub.status.idle":"2023-08-19T20:10:43.181527Z","shell.execute_reply.started":"2023-08-19T20:10:43.170987Z","shell.execute_reply":"2023-08-19T20:10:43.180340Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"['ID',\n 'Delivery_person_ID',\n 'Delivery_person_Age',\n 'Delivery_person_Ratings',\n 'Restaurant_latitude',\n 'Restaurant_longitude',\n 'Delivery_location_latitude',\n 'Delivery_location_longitude',\n 'Order_Date',\n 'Time_Orderd',\n 'Time_Order_picked',\n 'Weatherconditions',\n 'Road_traffic_density',\n 'Vehicle_condition',\n 'Type_of_order',\n 'Type_of_vehicle',\n 'multiple_deliveries',\n 'Festival',\n 'City_encodings',\n 'Time_taken(min)',\n 'City',\n 'city_zone']"},"metadata":{}}]},{"cell_type":"code","source":"df.select('Time_Orderd').dtypes","metadata":{"execution":{"iopub.status.busy":"2023-08-19T20:11:38.316591Z","iopub.execute_input":"2023-08-19T20:11:38.318146Z","iopub.status.idle":"2023-08-19T20:11:38.335902Z","shell.execute_reply.started":"2023-08-19T20:11:38.318088Z","shell.execute_reply":"2023-08-19T20:11:38.334665Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"[('Time_Orderd', 'string')]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<blockquote><p style=\"font-size:20px; color:#159364; font-family:verdana;\">6. Cleaning the target variable:</p></blockquote>","metadata":{}},{"cell_type":"code","source":"## Before transformation:\ndf.select(\"Time_taken(min)\").show(5)","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:34:36.429790Z","iopub.execute_input":"2023-08-17T20:34:36.430275Z","iopub.status.idle":"2023-08-17T20:34:36.518410Z","shell.execute_reply.started":"2023-08-17T20:34:36.430238Z","shell.execute_reply":"2023-08-17T20:34:36.517106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Renaming the column name::\ndf=df.withColumnRenamed('Time_taken(min)','time_taken')\n\n## Removing the preffix (i.e. '(min)') in the column values with the help of a UDF:\ndef target_clean(x):\n    return x[-2:]\n\ntarget_clean_udf=udf(lambda x:target_clean(x),StringType())\ndf=df.withColumn(\"time_taken\",target_clean_udf(col(\"time_taken\")))\n## Converting type:\ndf=df.withColumn(\"time_taken\",col(\"time_taken\").cast(IntegerType()))","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:34:39.455770Z","iopub.execute_input":"2023-08-17T20:34:39.456197Z","iopub.status.idle":"2023-08-17T20:34:39.507656Z","shell.execute_reply.started":"2023-08-17T20:34:39.456162Z","shell.execute_reply":"2023-08-17T20:34:39.506693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## As you can see, the values have been cleaned and the type has been changed:\ndf.select(\"time_taken\").show(5),df.select(\"time_taken\").dtypes","metadata":{"execution":{"iopub.status.busy":"2023-08-17T20:35:26.383056Z","iopub.execute_input":"2023-08-17T20:35:26.383461Z","iopub.status.idle":"2023-08-17T20:35:26.754811Z","shell.execute_reply.started":"2023-08-17T20:35:26.383432Z","shell.execute_reply":"2023-08-17T20:35:26.753783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<blockquote><p style=\"font-size:20px; color:#159364; font-family:verdana;\">7. Handling the Geo Data:</p></blockquote>","metadata":{}},{"cell_type":"code","source":"7. \n\n# from geopy.distance import geodesic \n\n# train['distance_diff_KM']=np.zeros(len(train))\n# restaurant_cordinates_train=train[['Restaurant_latitude','Restaurant_longitude']].to_numpy()\n# delivery_location_cordinates_train=train[['Delivery_location_latitude','Delivery_location_longitude']].to_numpy()\n\n# for i in range(len(train)):\n#     train['distance_diff_KM'].loc[i]=geodesic(restaurant_cordinates_train[i],delivery_location_cordinates_train[i])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}