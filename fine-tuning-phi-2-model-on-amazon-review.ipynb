{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Installing the necessary dependencies;\n\n!pip install -qq -U bitsandbytes transformers peft accelerate datasets scipy einops evaluate trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:00:56.371268Z","iopub.execute_input":"2025-05-06T17:00:56.371943Z","iopub.status.idle":"2025-05-06T17:02:22.869833Z","shell.execute_reply.started":"2025-05-06T17:00:56.371918Z","shell.execute_reply":"2025-05-06T17:02:22.869112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Importing the necessary libraries;\n\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    GenerationConfig\n)\nfrom tqdm import tqdm\nfrom trl import SFTTrainer\nimport torch\nimport time\nfrom huggingface_hub import login\n\nimport pandas as pd\nimport numpy as np\n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hf_token\")\n\n\n### Hide this later using the .env file;\nlogin(token=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:02:22.871106Z","iopub.execute_input":"2025-05-06T17:02:22.871338Z","iopub.status.idle":"2025-05-06T17:02:48.450296Z","shell.execute_reply.started":"2025-05-06T17:02:22.871314Z","shell.execute_reply":"2025-05-06T17:02:48.449758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### gets me the GPU memory used at any point of time\nfrom pynvml import *\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n\n\nprint_gpu_utilization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:02:50.832844Z","iopub.execute_input":"2025-05-06T17:02:50.833341Z","iopub.status.idle":"2025-05-06T17:02:50.839101Z","shell.execute_reply.started":"2025-05-06T17:02:50.833319Z","shell.execute_reply":"2025-05-06T17:02:50.838145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Loading the dataset;\n\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True)\nprint(dataset[\"full\"][0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:02:52.543548Z","iopub.execute_input":"2025-05-06T17:02:52.544290Z","iopub.status.idle":"2025-05-06T17:03:06.439514Z","shell.execute_reply.started":"2025-05-06T17:02:52.544264Z","shell.execute_reply":"2025-05-06T17:03:06.438953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Preprocessing;\nrating = pd.DataFrame(dataset['full']['rating'], columns = ['rating'])\nreview = pd.DataFrame(dataset['full']['text'], columns = ['review'])\n\n\n### Classify 1 as negative, 5 as positive\nconsol = pd.concat([rating, review], axis = 1)\nconsol = consol[consol.rating.isin([1,5])].reset_index(drop = True)\n\n## Creating a label;\nconsol['sentiment'] = consol.rating.map({1: 'Negative', 5: 'Positive'})\nconsol.drop(['rating'], axis = 1, inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:06.440787Z","iopub.execute_input":"2025-05-06T17:03:06.441374Z","iopub.status.idle":"2025-05-06T17:03:07.944611Z","shell.execute_reply.started":"2025-05-06T17:03:06.441347Z","shell.execute_reply":"2025-05-06T17:03:07.944018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert to Hugging Face Dataset\n\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\n\n## Splitting it into train and test;\ntest_size = 0.25\n\ntrain_df, test_df = train_test_split(consol, test_size = test_size)\n\n# Convert individual DataFrames\ntrain_dataset = Dataset.from_pandas(train_df)\ntest_dataset = Dataset.from_pandas(test_df)\n\n# Combine into a DatasetDict\ndataset = DatasetDict({\n    'train': train_dataset,\n    'test': test_dataset\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:07.945282Z","iopub.execute_input":"2025-05-06T17:03:07.945548Z","iopub.status.idle":"2025-05-06T17:03:08.968293Z","shell.execute_reply.started":"2025-05-06T17:03:07.945525Z","shell.execute_reply":"2025-05-06T17:03:08.967768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\n\ndel train_dataset, test_dataset\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:08.969996Z","iopub.execute_input":"2025-05-06T17:03:08.970226Z","iopub.status.idle":"2025-05-06T17:03:09.379556Z","shell.execute_reply.started":"2025-05-06T17:03:08.970209Z","shell.execute_reply":"2025-05-06T17:03:09.378878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:09.380388Z","iopub.execute_input":"2025-05-06T17:03:09.380889Z","iopub.status.idle":"2025-05-06T17:03:09.434525Z","shell.execute_reply.started":"2025-05-06T17:03:09.380853Z","shell.execute_reply":"2025-05-06T17:03:09.433869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Viewing a sample observation;\ndataset['train']['review'][0], dataset['train']['sentiment'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:09.435267Z","iopub.execute_input":"2025-05-06T17:03:09.435494Z","iopub.status.idle":"2025-05-06T17:03:10.257865Z","shell.execute_reply.started":"2025-05-06T17:03:09.435477Z","shell.execute_reply":"2025-05-06T17:03:10.257222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Model Definition for fine tuning\n\n\n## Defining the bnb congif for loading the model in a quantised fashion; \ncompute_dtype = getattr(torch, \"float16\")\nbnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type='nf4',\n        bnb_4bit_compute_dtype=compute_dtype,\n        bnb_4bit_use_double_quant=False,\n    )\n\ndevice_map = {\"\": 0}\n\n\n## Loading the model;\nmodel_name='microsoft/phi-2'\noriginal_model = AutoModelForCausalLM.from_pretrained(model_name, \n                                                      device_map=device_map,\n                                                      quantization_config=bnb_config,\n                                                      trust_remote_code=True,\n                                                      use_auth_token=True)\n\n\nprint_gpu_utilization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:06:17.694386Z","iopub.execute_input":"2025-05-06T17:06:17.694657Z","iopub.status.idle":"2025-05-06T17:06:46.943763Z","shell.execute_reply.started":"2025-05-06T17:06:17.694639Z","shell.execute_reply":"2025-05-06T17:06:46.943031Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print_gpu_utilization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:06:46.945153Z","iopub.execute_input":"2025-05-06T17:06:46.945792Z","iopub.status.idle":"2025-05-06T17:06:46.949467Z","shell.execute_reply.started":"2025-05-06T17:06:46.945773Z","shell.execute_reply":"2025-05-06T17:06:46.948846Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"### Tokeniser\n\n## Loading the tokenizer;\nmodel_name='microsoft/phi-2'\ntokenizer = AutoTokenizer.from_pretrained(model_name,\n                                          trust_remote_code=True,\n                                          padding_side=\"left\",\n                                          add_eos_token=True,\n                                          add_bos_token=True,\n                                          use_fast=False)\ntokenizer.pad_token = tokenizer.eos_token\n\n\nprint_gpu_utilization()\n\n### Converting the text into the given prompt fashion","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:25.595845Z","iopub.execute_input":"2025-05-06T17:03:25.596381Z","iopub.status.idle":"2025-05-06T17:03:30.189753Z","shell.execute_reply.started":"2025-05-06T17:03:25.596356Z","shell.execute_reply":"2025-05-06T17:03:30.189055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_tokenizer = AutoTokenizer.from_pretrained(model_name, \n                                               add_bos_token=True, \n                                               trust_remote_code=True, \n                                               use_fast=False)\n\neval_tokenizer.pad_token = eval_tokenizer.eos_token\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:53.430284Z","iopub.execute_input":"2025-05-06T17:03:53.430562Z","iopub.status.idle":"2025-05-06T17:03:53.700223Z","shell.execute_reply.started":"2025-05-06T17:03:53.430542Z","shell.execute_reply":"2025-05-06T17:03:53.699670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def gen(model,p, maxlen=100, sample=True):\n    toks = eval_tokenizer(p, return_tensors=\"pt\")\n    res = model.generate(**toks.to(\"cuda\"), max_new_tokens=maxlen, do_sample=sample,num_return_sequences=1,temperature=0.1,num_beams=1,top_p=0.95,).to('cpu')\n    return eval_tokenizer.batch_decode(res,skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:06:55.625766Z","iopub.execute_input":"2025-05-06T17:06:55.626330Z","iopub.status.idle":"2025-05-06T17:06:55.630665Z","shell.execute_reply.started":"2025-05-06T17:06:55.626306Z","shell.execute_reply":"2025-05-06T17:06:55.629812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import set_seed\nseed = 42\nset_seed(seed)\n\nindex = 12\n\nreview = dataset['train']['review'][index]\nsentiment = dataset['train']['sentiment'][index]\n\nformatted_prompt = f\"Instruct: You are a sentiment analyser, that tries to classify the sentiment of a e-commerce review into one of these - 'Positive' or 'Negative'. Classify the following review: \\n{review}\\nOutput:\\n\"\n\n\nres = gen(original_model,formatted_prompt,100,)\n\n#print(res[0])\noutput = res[0].split('Output:\\n')[1]\n\ndash_line = '-'.join('' for x in range(100))\nprint(dash_line)\nprint(f'INPUT PROMPT:\\n{formatted_prompt}')\nprint(dash_line)\nprint(f'BASELINE HUMAN SUMMARY:\\n{sentiment}\\n')\nprint(dash_line)\nprint(f'MODEL GENERATION - ZERO SHOT:\\n{output}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:19:12.623516Z","iopub.execute_input":"2025-05-06T17:19:12.624228Z","iopub.status.idle":"2025-05-06T17:19:13.699231Z","shell.execute_reply.started":"2025-05-06T17:19:12.624203Z","shell.execute_reply":"2025-05-06T17:19:13.698614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}